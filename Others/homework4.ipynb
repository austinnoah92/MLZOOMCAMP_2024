{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "502 Server Error: Bad Gateway for url: https://archive.ics.uci.edu/static/public/222/bank+marketing.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Stream the outer zip file from the URL\u001b[39;00m\n\u001b[1;32m     12\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure the request was successful\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent)) \u001b[38;5;28;01mas\u001b[39;00m outer_zip:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Extract the inner zip file (bank.zip)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m outer_zip\u001b[38;5;241m.\u001b[39mopen(inner_zip_file) \u001b[38;5;28;01mas\u001b[39;00m inner_zip_stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 502 Server Error: Bad Gateway for url: https://archive.ics.uci.edu/static/public/222/bank+marketing.zip"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\"\n",
    "inner_zip_file = \"bank.zip\"\n",
    "csv_file = \"bank-full.csv\"\n",
    "\n",
    "# Stream the outer zip file from the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Ensure the request was successful\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as outer_zip:\n",
    "    # Extract the inner zip file (bank.zip)\n",
    "    with outer_zip.open(inner_zip_file) as inner_zip_stream:\n",
    "        with zipfile.ZipFile(io.BytesIO(inner_zip_stream.read())) as inner_zip:\n",
    "            # Extract the CSV file from the inner zip file\n",
    "            with inner_zip.open(csv_file) as file:\n",
    "                df = pd.read_csv(file, sep=';')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "columns = [\"age\", \"job\", \"marital\", \"education\", \"balance\", \"housing\", \"contact\", \"day\", \"month\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"poutcome\", \"y\"]\n",
    "\n",
    "df = df[columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "# Target Encoding\n",
    "\n",
    "df['y'] = df['y'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "\n",
    "#Train_Test_Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.copy()\n",
    "\n",
    "X_train_full, X_test = train_test_split(X, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train, X_val = train_test_split(X_train_full, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "df_train_full = X_train_full.reset_index(drop=True)\n",
    "df_train = X_train.reset_index(drop=True)\n",
    "df_val = X_val.reset_index(drop =True)\n",
    "df_test = X_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.y.values\n",
    "y_val = df_val.y.values\n",
    "y_test = df_test.y.values\n",
    "\n",
    "del df_train['y']\n",
    "del df_val['y']\n",
    "del df_test['y']                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(train, val, y_train, y_val, features):\n",
    "    train_dict = train[features].to_dict(orient='records')\n",
    "    val_dict = val[features].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    x_train = dv.fit_transform(train_dict)\n",
    "    x_val = dv.transform(val_dict)\n",
    "\n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    return roc_auc_score(y_val, y_pred)\n",
    "\n",
    "def train_and_evaluate_allfeat(train, val, y_train, y_val):\n",
    "    train_dict = train.to_dict(orient='records')\n",
    "    val_dict = val.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    x_train = dv.fit_transform(train_dict)\n",
    "    x_val = dv.transform(val_dict)\n",
    "\n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    return roc_auc_score(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC feature importance\n",
    "\n",
    "feat = ['balance', 'day', 'duration', 'previous']\n",
    "score = {}\n",
    "\n",
    "for n in feat:\n",
    "    aucscore = roc_auc_score(y_train, df_train[n])\n",
    "    if aucscore < 0.5:\n",
    "        aucscore = roc_auc_score(y_train, -df_train[n])\n",
    "    score[n] = aucscore\n",
    "\n",
    "max_score = max(score, key=score.get)\n",
    "print(f\"The numerical variable with the highest AUC is: {max_score} with an AUC of {score[max_score]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression and auc_score\n",
    "\n",
    "scores = train_and_evaluate_allfeat(df_train, df_val, y_train, y_val)\n",
    "auc_scores = round(scores, 3)\n",
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and Recall\n",
    "# Define the start, stop, and step size\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "start = 0\n",
    "stop = 1\n",
    "step = 0.01\n",
    "\n",
    "# Calculate the number of samples\n",
    "num_samples = int((stop - start) / step) + 1\n",
    "\n",
    "def train_and_evaluate_allfeat1(train, val, y_train, y_val):\n",
    "    train_dict = train.to_dict(orient='records')\n",
    "    val_dict = val.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    x_train = dv.fit_transform(train_dict)\n",
    "    x_val = dv.transform(val_dict)\n",
    "\n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict_proba(x_val)[:, 1]\n",
    "    return y_pred\n",
    "\n",
    "thresh = np.linspace(start, stop, num=num_samples)\n",
    "y_pred = train_and_evaluate_allfeat1(df_train, df_val, y_train, y_val)\n",
    "\n",
    "# Initialize lists to store precision and recall scores\n",
    "pre_scores = []\n",
    "rec_scores = []\n",
    "\n",
    "for i in thresh:\n",
    "    # Binarize predictions based on the threshold\n",
    "    y_pred_binary = (y_pred >= i).astype(int)\n",
    "    \n",
    "    # Compute precision and recall scores\n",
    "    pre_score = precision_score(y_val, y_pred_binary)\n",
    "    rec_score = recall_score(y_val, y_pred_binary)\n",
    "    \n",
    "    # Append the scores to the lists\n",
    "    pre_scores.append(pre_score)\n",
    "    rec_scores.append(rec_score)\n",
    "\n",
    "# Plot precision and recall curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresh, pre_scores, label='Precision')\n",
    "plt.plot(thresh, rec_scores, label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the threshold where precision and recall intersect\n",
    "intersection_threshold = thresh[np.argmin(np.abs(np.array(pre_scores) - np.array(rec_scores)))]\n",
    "print(f\"The threshold at which precision and recall curves intersect is: {intersection_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
